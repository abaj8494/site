+++
title = "MNIST and FMNIST using KNN"
tags = ["knn", "fmnist", "mnist", "non-parametric"]
toc = "true"
math = "true"
+++

{{< collapse folded="false">}}


old mate yann lecunn decided to remove the mnist zip from his site along with the corresponding file info

* data specification:

[[/code/10khrs-ai-ml-dl/PROJECTS/ocr/data/][here]] are the original archives

and here is the file spec after digging it out of the wayback machine.
#+begin_src
TRAINING SET LABEL FILE (train-labels-idx1-ubyte):
[offset] [type]          [value]          [description]
0000     32 bit integer  0x00000801(2049) magic number (MSB first)
0004     32 bit integer  60000            number of items
0008     unsigned byte   ??               label
0009     unsigned byte   ??               label
........
xxxx     unsigned byte   ??               label
The labels values are 0 to 9.

TRAINING SET IMAGE FILE (train-images-idx3-ubyte):
[offset] [type]          [value]          [description]
0000     32 bit integer  0x00000803(2051) magic number
0004     32 bit integer  60000            number of images
0008     32 bit integer  28               number of rows
0012     32 bit integer  28               number of columns
0016     unsigned byte   ??               pixel
0017     unsigned byte   ??               pixel
........
xxxx     unsigned byte   ??               pixel
Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).

TEST SET LABEL FILE (t10k-labels-idx1-ubyte):
[offset] [type]          [value]          [description]
0000     32 bit integer  0x00000801(2049) magic number (MSB first)
0004     32 bit integer  10000            number of items
0008     unsigned byte   ??               label
0009     unsigned byte   ??               label
........
xxxx     unsigned byte   ??               label
The labels values are 0 to 9.

TEST SET IMAGE FILE (t10k-images-idx3-ubyte):
[offset] [type]          [value]          [description]
0000     32 bit integer  0x00000803(2051) magic number
0004     32 bit integer  10000            number of images
0008     32 bit integer  28               number of rows
0012     32 bit integer  28               number of columns
0016     unsigned byte   ??               pixel
0017     unsigned byte   ??               pixel
........
xxxx     unsigned byte   ??               pixel
Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).
#+end_src

* no imports

originally I followed this fellas youtube video:
{{< youtube vzabeKdW9tE >}}

creating the following =main.py= file.

** code
#+INCLUDE: "/code/10khrs-ai-ml-dl/PROJECTS/ocr/original.py" src python

** results
and this worked okay on a few samples:
#+BEGIN_SRC
dataset: mnist
n_train: 10000
n_test: 100
k: 7
Predicted labels: ...
Accuracy: 95.0%
#+END_SRC

but given that I wanted to (and I could with the help of UNSW's HPC Katana,) run the algorithm on the entire dataset, I quickly learned that the above code ran a single process on a single CPU core.

using =tmux= in a HPC over ~100hrs of compute I was able to produce:

#+BEGIN_SRC
dataset: mnist
n_train: 60000
n_test: 10000
k: 5
Predicted labels: ...
Accuracy: 96.93%
#+END_SRC

however, re-running this for =fmnist= was out of the question.

as such I turned to other methods:

* multiprocessing

I was advised by the sysadmin of katana to use either =joblib= or =multiprocessing=.

my solution with this approach was to simply add the relevant =import= and refactor the main =knn= loop as

#+begin_src python
def knn(X_train, y_train, X_test, k=3):
    with Pool(processes=multiprocessing.cpu_count()) as pool:
        work_items = [(test_sample_idx, test_sample, X_train, y_train, k) for test_sample_idx, test_sample in enumerate(X_test)]
        y_pred = pool.map(classify_one, work_items)
    return y_pred
#+end_src

this approach ended up using the 6, 8, 36, etc. cores that I had available.

still only a 10x-20x speed-up --- runtimes now of still 10 hours.

* multithreading

I then thought of giving each of these 8 or so CPU cores 20 threads to manage.

#+begin_src
Dataset: fmnist
n_train: 60000
n_test: 10000
k: 7
Accuracy: 85.41%
#+end_src

however it is worth noting that each of these threads share the memory address space of the parent process.

as such, due to the way python handles its GIL, a computational speed up was /not/ guaranteed.

I let chatgpt draft the code:

** code

#+INCLUDE: "/code/10khrs-ai-ml-dl/PROJECTS/ocr/multithreaded.py" src python

* vectorising

finally, I realised that we could sidestep all of this by leveraging the =numpy= library and it's underlying parallelism of array operations.

#+BEGIN_SRC python
Dataset: mnist
n_train: 60000
n_test: 10000
k: 7
chunk_size: 1000
Shapes: (60000, 784) (60000,) (10000, 784) (10000,)
Processed 1000 / 10000 test samples
Processed 6000 / 10000 test samples
Accuracy: 96.94%

real    0m12.106s
user    0m20.951s
sys     0m2.137s
#+END_SRC

note that we have now gone from a 100hr inference time to a 12 second inference time!

** analysis

furthermore, we must also notice that the above calculation takes place in partitions. the reason for this is the below calculation:

*** calculation
for each of the \(10,000\) training samples we do \(60,000\) comparisons. thus a total of 600 *Million* comparisons. each of these image comparisons compares a \(784 \times 1 \) dimensional vector with another.

previously when we were manually doing these loops that would mean \(\approx\) 4.704 *Billion* calculations. furthermore if we encode all of these as =float32='s of 4 bytes each, suddenly we require 1.8 Terabytes of RAM to hold all these numbers.

** code

making a chunk size of 1,000, we have this (chatgpt o1) code:

#+INCLUDE: "/code/10khrs-ai-ml-dl/PROJECTS/ocr/n00m.py" src python


* frameworks

using [[https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html][scikit-learn]]'s =KNeigborsClassifier= we have

** code

#+INCLUDE: "/code/10khrs-ai-ml-dl/PROJECTS/ocr/ski.py" src python

** results

it's reassuring to see that our algorithm is deterministic across the dataset:
#+begin_src
Dataset: mnist
n_train: 60000
n_test: 10000
k: 7
Shapes:
X_train: (60000, 784) y_train: (60000,)
X_test: (10000, 784) y_test: (10000,)
Accuracy: 96.94%

real    0m27.286s
user    1m10.678s
sys     0m7.199s
#+end_src

then for fmnist:
#+begin_src
Dataset: fmnist
n_train: 60000
n_test: 10000
k: 7
Shapes:
X_train: (60000, 784) y_train: (60000,)
X_test: (10000, 784) y_test: (10000,)
Accuracy: 85.40%

real    0m26.802s
user    1m8.035s
sys     0m6.987s
#+end_src

as expected :)

which interestingly loses to our numpy chunking approach!


* Construction Babel Code ⚒️                                        :noexport:

#+begin_src python :noweb yes :session test :tangle /Users/aayushbajaj/Documents/new-site/static/code/10khrs-ai-ml-dl/PROJECTS/ocr/main.py
  DATA_DIR = 'data/'
  DATASET = 'fmnist'
  TEST_DATA_FILENAME = DATA_DIR + DATASET + '/t10k-images-idx3-ubyte'
  TEST_LABELS_FILENAME = DATA_DIR + DATASET + '/t10k-labels-idx1-ubyte'
  TRAIN_DATA_FILENAME = DATA_DIR + DATASET + '/train-images-idx3-ubyte'
  TRAIN_LABELS_FILENAME = DATA_DIR + DATASET + '/train-labels-idx1-ubyte'


  def bytes_to_int(byte_data):
      return int.from_bytes(byte_data, 'big')


  <<read>>


  def flatten_list(subl):
      return [pixel for sublist in subl for pixel in sublist]


  def extract_features(X):
      return [flatten_list(sample) for sample in X]


  <<classify-one>>


  <<knn-parallel>>


  <<garments>>


  def main():
      n_train = 1000
      n_test = 10
      k = 7
      print(f"Dataset: {DATASET}")
      print(f"n_train: {n_train}")
      print(f"n_test: {n_test}")
      print(f"k: {k}")
      X_train = read_images(TRAIN_DATA_FILENAME, n_train)
      y_train = read_labels(TRAIN_LABELS_FILENAME, n_train)
      X_test = read_images(TEST_DATA_FILENAME, n_test)
      y_test = read_labels(TEST_LABELS_FILENAME, n_test)
      X_train = extract_features(X_train)
      X_test = extract_features(X_test)

      y_pred = knn(X_train, y_train, X_test, k)

      accuracy = sum([
	  int(y_pred_i == y_test_i)
	  for y_pred_i, y_test_i in zip(y_pred, y_test)
      ]) / len(y_test)

      if DATASET == 'fmnist':
	  garments_pred = [
	      get_garment_from_label(label)
	      for label in y_pred
	  ]
	  print(f"Predicted garments: {garments_pred}")
      else:
	  print(f"Predicted labels: {y_pred}")

      print(f"Accuracy: {accuracy * 100}%")

    
  if __name__ == '__main__':
      main()

#+end_src


#+name: classify-one
#+begin_src python
  def classify_one(args):
      test_sample_idx, test_sample, X_train, y_train, k = args # unpack args
      print(test_sample_idx)
      training_distances = [dist(train_sample, test_sample) for train_sample in X_train]
      sorted_distance_indices = [
	  pair[0]
	  for pair in sorted(enumerate(training_distances), key=lambda x: x[1])
      ]
      candidates = [y_train[idx] for idx in sorted_distance_indices[:k]]
      top_candidate = max(candidates, key=candidates.count)
      return top_candidate
#+end_src

#+name: knn-parallel
#+begin_src python
  from multiprocessing import Pool
  import multiprocessing

  def dist(x, y):
      return sum(
	  [
	      (bytes_to_int(x_i) - bytes_to_int(y_i)) ** 2
	      for x_i, y_i in zip(x, y)]
      ) ** 0.5


  def knn(X_train, y_train, X_test, k=3):
      with Pool(processes=multiprocessing.cpu_count()) as pool:
	  work_items = [(test_sample_idx, test_sample, X_train, y_train, k) for test_sample_idx, test_sample in enumerate(X_test)]
	  y_pred = pool.map(classify_one, work_items)
      return y_pred
#+end_src

#+name: read
#+begin_src python
def read_images(filename, n_max_images=None):
    images = []
    with open(filename, 'rb') as f:
        _ = f.read(4)
        n_images = bytes_to_int(f.read(4))
        if n_max_images:
            n_images = n_max_images
        n_rows = bytes_to_int(f.read(4))
        n_cols = bytes_to_int(f.read(4))
        for image_idx in range(n_images):
            image = []
            for row_idx in range(n_rows):
                row = []
                for col_idx in range(n_cols):
                    pixel = f.read(1)
                    row.append(pixel)
                image.append(row)
            images.append(image)
        return images

    
def read_labels(filename, n_max_labels=None):
    labels = []
    with open(filename, 'rb') as f:
        _ = f.read(4)  # magic number
        n_labels = bytes_to_int(f.read(4))
        if n_max_labels:
            n_labels = n_max_labels
        for label_idx in range(n_labels):
            label = bytes_to_int(f.read(1))
            labels.append(label)
    return labels
#+end_src

#+name: knn
#+begin_src python
def dist(x, y):
    return sum(
        [
            (bytes_to_int(x_i) - bytes_to_int(y_i)) ** 2
            for x_i, y_i in zip(x, y)]
    ) ** 0.5


def get_training_distances_for_test_sample(X_train, test_sample):
    return [dist(train_sample, test_sample) for train_sample in X_train]


def knn(X_train, y_train, X_test, y_test, k=3):
    y_pred = []
    for test_sample_idx, test_sample in enumerate(X_test):
        training_distances = get_training_distances_for_test_sample(
            X_train, test_sample
        )
        sorted_distance_indices = [
            pair[0]
            for pair in sorted(
                    enumerate(training_distances),
                    key=lambda x: x[1]
            )
        ]
        candidates = [
            y_train[idx]
            for idx in sorted_distance_indices[:k]
        ]
        top_candidate = max(candidates, key=candidates.count)
        y_pred.append(top_candidate)
    return y_pred
#+end_src

#+name: garments
#+begin_src python 
def get_garment_from_label(label):
    return [
        'T-shirt/top',
        'Trouser',
        'Pullover',
        'Dress',
        'Coat',
        'Sandal',
        'Shirt',
        'Sneaker',
        'Bag',
        'Ankle boot',
    ][label]
#+end_src

(setq org-src-preserve-indentation nil 
      org-edit-src-content-indentation 0)

* Results

** FMNIST
#+BEGIN_SRC
n_train: 10000
n_test: 100
k: 7
Predicted labels: ...
Accuracy: 95.0%
#+END_SRC

** MNIST



The _whole_ dataset:
